{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 크롤링 크롤링 우\n",
    "\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.naver.com'\n",
    "\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_data = response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(html_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# str에서 문자를 찾고 싶을 때 index() | find() 사용\n",
    "    # index()에서 찾는 문자가 없을 땐 error -> try / except 사용 가능\n",
    "    # find()에서 찾는 문자가 없을 땐 -1 return -> if문 사용 가능\n",
    "\n",
    "## html_data에서 '네이버' 문자열의 위치를 검색\n",
    "\n",
    "print(html_data.find('네이버'))\n",
    "print(html_data.index('네이버'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_data[378:381]\n",
    "\n",
    "# 이런 방식은 너무 효율이 떨어짐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bs4 라이브러리\n",
    "- bs4 라이브러리 안에 있는 BeautifulSoup Class를 사용\n",
    "- html로 이루어진 문자형 데이터를 parsing 작업을 하여 데이터를 쉽게 추출하기 위한 Class\n",
    "    - parsing\n",
    "        - 데이터의 타입을 변경(Class 안에 데이터를 대입)\n",
    "- html의 TAG를 기준으로 데이터(contents)를 쉽게 추출하기 위해 사용\n",
    "- 웹의 구조를 어느정도 파악하고 사용하게 되면 쉽게 접근이 가능\n",
    "- Parser를 활용해서 파이썬에서의 접근을 쉽게하기 위해 객체(변수 + 함수)의 형태로 제공\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 라이브러리 설치\n",
    "\n",
    "# !pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 로드\n",
    "\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# html로 이루어진 문자열을 bs Class에 대입시켜 parsing\n",
    "    # 데이터, 파싱할 데이터의 형태\n",
    "\n",
    "soup = bs(html_data, 'html.parser') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 태그의 이름을 기준으로 검색(필터)\n",
    "    - soup.태그명 == 해당 태그명의 첫번째 태그를 출력\n",
    "    - soup.태그명.string == 첫번째 태그의 문자열(contents)을 출력\n",
    "        - ex) `<p>test</p>` --> test\n",
    "    - soup.태그명['속성명'] == 첫번째 태그의 해당 속성의 값을 출력\n",
    "        - ex) `<a herf = 'https://www.google.com'>구글</a>` == 'https://www.google.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.a.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.a['href']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- find()\n",
    "    - html 데이터에서 특정 태그의 첫번째 정보를 출력\n",
    "    - find(속성명 = 속성값) == 태그들 중 해당 속성명과 속성값이 같은 첫번째 태그의 정보를 출력\n",
    "    - 결과 데이터가 TAG의 형태로 출력 (문자열로 생각하면 문자 데이터)\n",
    "    - BeautifulSoup에서 상속받아 함수 적용 가능\n",
    "\n",
    "- find_all()\n",
    "    - html 데이터에서 특정 태그의 모든 정보를 출력\n",
    "    - limit 매개변수 == 출력해주는 데이터의 갯수를 지정\n",
    "    - 결과 데이터가 TAG들의 집합인 ResultSet 형태로 출력 (문자열로 생각하면 list 데이터)\n",
    "    - BeautifulSoup에서 상속받지 못하기에 함수 적용 불가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(soup.a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(soup.find_all('a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(soup.find('a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(soup.find_all('a'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tag.string과 tag.get_text()의 차이\n",
    "\n",
    "- tag.string\n",
    "    - 태그에 contents가 여러개인 경우 어떤 것을 추출해야 할 지 몰라 None이 나옴\n",
    "\n",
    "- tag.get_text()\n",
    "    - 태그에 contents가 여러개인 경우 모든 contents들을 추출해오기 때문에 한 태그에서 여러개의 contents가 추출됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TAG 형태로 되어있는 데이터에서 contents를 추출\n",
    "\n",
    "a_data = soup.find('a')\n",
    "\n",
    "print(a_data)\n",
    "print(a_data.string)\n",
    "print(a_data.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ResultSet 형태로 되어있는 데이터에서 contents 출력\n",
    "\n",
    "a_list = soup.find_all('a')\n",
    "\n",
    "print(a_list)\n",
    "# print(a_list.string) # error\n",
    "# print(a_list.get_text()) # error\n",
    "\n",
    "print(a_list[0].string) # list 안의 원소인 TAG로 변환해서 사용\n",
    "print(a_list[1].get_text()) # list 안의 원소인 TAG로 변환해서 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_list = []\n",
    "\n",
    "for i in range(len(a_list)):\n",
    "    _list.append(a_list[i].get_text())\n",
    "\n",
    "_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_list = []\n",
    "\n",
    "a_list = soup.find_all('a')\n",
    "\n",
    "for i in a_list:\n",
    "    _list.append(i.get_text())\n",
    "\n",
    "_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_list = []\n",
    "\n",
    "j = 0\n",
    "\n",
    "a_list = soup.find_all('a')\n",
    "\n",
    "while j < len(a_list):\n",
    "    _list.append(a_list[j].get_text())\n",
    "    j += 1\n",
    "\n",
    "_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# while 무한반복\n",
    "\n",
    "i = 0\n",
    "\n",
    "_list = []\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        _list.append(a_list[i].get_text())\n",
    "        i += 1\n",
    "    except:\n",
    "        break\n",
    "\n",
    "_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이썬 기본 함수 map // map()하면 mapping 데이터가 나오기에 이를 list 형태로 다시 parsing 해야 함\n",
    "\n",
    "_list = []\n",
    "\n",
    "a_list = soup.find_all('a')\n",
    "\n",
    "list(map(lambda x : _list.append(x.get_text()), a_list)) # list() 형태로 만들기\n",
    "\n",
    "_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이썬 일반 함수인 map() 사용\n",
    "\n",
    "def noway(x):\n",
    "    return x.get_text()\n",
    "\n",
    "_list = []\n",
    "\n",
    "a_list = soup.find_all('a')\n",
    "\n",
    "list(\n",
    "    map(\n",
    "    noway,\n",
    "    a_list\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas 내장함수인 map() 사용\n",
    "\n",
    "_list = []\n",
    "\n",
    "a_list = soup.find_all('a')\n",
    "\n",
    "a_list = pd.Series(a_list)\n",
    "\n",
    "a_list.map(\n",
    "    lambda x : _list.append(x.get_text())\n",
    ")\n",
    "\n",
    "_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## naver html 문서에서 div 태그 중 id가 newsstand인 태그를 추출\n",
    "\n",
    "soup.find('div', attrs= {'id' : 'newsstand'})\n",
    "\n",
    "# 아무런 것도 출력되지 않는 이유는 naver가 동적인 페이지이고, 빠른 로드를 위해 일부 코드만을 처음 로드한 후 나머지 코드들을 로드하는 방식으로 동작\n",
    "    # 따라서 초기에 로드된 코드들에 attrs 조건을 만족하는 데이터가 없어서 출력이 되지 않았던 것. 이 때문에 selenium이 필요함\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 주소로 요청을 보낸다\n",
    "\n",
    "_url = 'https://finance.naver.com/'\n",
    "\n",
    "response2 = requests.get(_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_data2 = response2.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## BeautifulSoup를 이용하여 데이터를 parsing\n",
    "\n",
    "soup2 = bs(html_data2, 'html.parser')\n",
    "\n",
    "soup2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# div 태그 중 class가 section_sise_top인 태그의 갯수를 확인\n",
    "\n",
    "len(soup2.find_all('div', attrs={\n",
    "    'class' : 'section_sise_top'\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "div_data = soup2.find('div', attrs={\n",
    "    'class' : 'section_sise_top'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "div_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# div_data에서 table 태그의 갯수를 확인\n",
    "    # 4개가 찍히는건 4개의 구획으로 나뉘어서 각 구획을 클릭할 시 화면에 띄워주는 방식을 택하고 있기에 4개가 나오는 것 :>\n",
    "    # 현재 동작중인 구획은 class에 is_active가 있다\n",
    "\n",
    "len(div_data.find_all(\n",
    "    'table'\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table 태그의 데이터들을 변수에 저장\n",
    "\n",
    "tables = div_data.find_all('table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tables의 첫 번째 태그를 이용하여 데이터를 추출하여 데이터 프레임으로 생성\n",
    "\n",
    "_table = tables[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## _table에서 thead를 추출\n",
    "\n",
    "head_data = _table.find('thead')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th_data = head_data.find_all('th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_col = list(\n",
    "    map(\n",
    "        lambda x: x.get_text(),\n",
    "    th_data\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbody_data = _table.find('tbody')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## tbody_data에서 tr 태그들을 모두 찾는다\n",
    "\n",
    "tr_data = tbody_data.find_all('tr')\n",
    "\n",
    "tr_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tr_data에서 첫 번째 원소를 추출하여 contents들을 list로 생성\n",
    "\n",
    "_val = [tr_data[0].find('th').get_text()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i를 text (str)로 받아오니까 문자 형태, 따라서 공백 제거 함수인 strip 사용 가능\n",
    "\n",
    "for i in tr_data[0].find_all('td'):\n",
    "    # print(i.get_text().strip())\n",
    "    _val.append(i.get_text().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위의 코드를 반복 실행하여 새로운 빈 list에 추가\n",
    "\n",
    "_values = []\n",
    "\n",
    "# th 태그에 포함된 contents 들고오기\n",
    "\n",
    "for i in range(len(tr_data)):\n",
    "    _val = [tr_data[i].find('th').get_text()]\n",
    "    \n",
    "    # td 태그에 포함된 contents 들고오기\n",
    "    \n",
    "    for j in tr_data[i].find_all('td'):\n",
    "        _val.append(j.get_text().strip())\n",
    "    _values.append(_val)\n",
    "\n",
    "_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df = pd.DataFrame(_values, columns= _col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df.columns = _col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df.to_csv('./Data_out/text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이제 4개의 table들을 가져오는 반복문을 만들어 보자\n",
    "\n",
    "cnt = 1 # globals에 1씩 증가시키기 위해 작성\n",
    "\n",
    "# 4개의 table들에 모두 동일한 작업을 적용하기 위해 반복문 작성\n",
    "\n",
    "for _table in tables:\n",
    "    \n",
    "    # _table에서 thead 태그를 모두 추출\n",
    "\n",
    "    thead_data = _table.find('thead')\n",
    "    _col = []\n",
    "\n",
    "    # 추출한 thead 태그를 df의 column으로 만들기 위해 _col에 넣어준다\n",
    "\n",
    "    for tag in thead_data.find_all('th'):\n",
    "        _col.append(tag.get_text())\n",
    "\n",
    "    # _table에서 df의 value를 담당하는 tbody 태그의 contents들을 모두 추출\n",
    "\n",
    "    tbody_data = _table.find('tbody')\n",
    "    \n",
    "    _values = []\n",
    "\n",
    "    # table들의 contents가 tr과 td로 나뉘어져 있다.\n",
    "        # tr 태그에 포함된 contents들과 td 태그에 포함된 contents들을 모두 추출해 _values에 넣어줘야 한다\n",
    "        # tr 하나에 td 3개가 붙어있으니 tr 하나에 대한 반복문 속 3번 반복하는 td 반복문을 작성해야 한다.\n",
    "\n",
    "    tr_data = tbody_data.find_all('tr')\n",
    "    \n",
    "    # th 태그에 포함된 contents 들고오기\n",
    "\n",
    "    for tag in tr_data:\n",
    "        \n",
    "        _val = [tag.find('th').get_text()]\n",
    "    \n",
    "        # td 태그에 포함된 contents 들고오기\n",
    "    \n",
    "        for tag2 in tag.find_all('td'):\n",
    "            _val.append(tag2.get_text().strip())\n",
    "        \n",
    "        _values.append(_val)\n",
    "\n",
    "    # 데이터 프레임을 생성하여 글로벌 변수에 대입\n",
    "\n",
    "    globals()[f'df{cnt}'] = pd.DataFrame(_values, columns= _col)\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df = pd.concat([df1, df2, df3, df4], ignore_index= True)\n",
    "\n",
    "df1.to_csv('./Data_out/거래상위.csv')\n",
    "df2.to_csv('./Data_out/상승장.csv')\n",
    "df3.to_csv('./Data_out/하락장.csv')\n",
    "df4.to_csv('./Data_out/시가총액_상위.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_20372\\1678411445.py:9: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  wtf = pd.read_html(div_str)\n"
     ]
    }
   ],
   "source": [
    "# pandas의 위대함 (table 태그 담당일진)\n",
    "\n",
    "    # tag 데이터를 str로 변환\n",
    "\n",
    "div_str = str(div_data)\n",
    "\n",
    "    # html 데이터로 읽어와서 table 데이터들을 자동으로 DataFrame으로 변환\n",
    "\n",
    "wtf = pd.read_html(div_str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>종목명</th>\n",
       "      <th>현재가</th>\n",
       "      <th>전일대비</th>\n",
       "      <th>등락률</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>스타리츠</td>\n",
       "      <td>4830</td>\n",
       "      <td>하한가 -2,060</td>\n",
       "      <td>-29.90%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>대상홀딩스우</td>\n",
       "      <td>14650</td>\n",
       "      <td>하락 -4,220</td>\n",
       "      <td>-22.36%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>디에이테크놀로지</td>\n",
       "      <td>207</td>\n",
       "      <td>하락 -57</td>\n",
       "      <td>-21.59%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>동신건설</td>\n",
       "      <td>20700</td>\n",
       "      <td>하락 -5,200</td>\n",
       "      <td>-20.08%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>화천기계</td>\n",
       "      <td>4395</td>\n",
       "      <td>하락 -1,005</td>\n",
       "      <td>-18.61%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>덕성우</td>\n",
       "      <td>9960</td>\n",
       "      <td>하락 -2,220</td>\n",
       "      <td>-18.23%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>에이텍</td>\n",
       "      <td>13820</td>\n",
       "      <td>하락 -2,710</td>\n",
       "      <td>-16.39%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>오리엔트정공</td>\n",
       "      <td>1409</td>\n",
       "      <td>하락 -273</td>\n",
       "      <td>-16.23%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>테고사이언스</td>\n",
       "      <td>20600</td>\n",
       "      <td>하락 -3,600</td>\n",
       "      <td>-14.88%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>태양금속우</td>\n",
       "      <td>3410</td>\n",
       "      <td>하락 -580</td>\n",
       "      <td>-14.54%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>디티앤씨알오</td>\n",
       "      <td>6240</td>\n",
       "      <td>하락 -1,040</td>\n",
       "      <td>-14.29%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>대영포장</td>\n",
       "      <td>1380</td>\n",
       "      <td>하락 -223</td>\n",
       "      <td>-13.91%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>솔루스첨단소재1우</td>\n",
       "      <td>3315</td>\n",
       "      <td>하락 -520</td>\n",
       "      <td>-13.56%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>토탈소프트</td>\n",
       "      <td>4880</td>\n",
       "      <td>하락 -730</td>\n",
       "      <td>-13.01%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>에이텍모빌리티</td>\n",
       "      <td>14000</td>\n",
       "      <td>하락 -1,980</td>\n",
       "      <td>-12.39%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          종목명    현재가        전일대비      등락률\n",
       "0        스타리츠   4830  하한가 -2,060  -29.90%\n",
       "1      대상홀딩스우  14650   하락 -4,220  -22.36%\n",
       "2    디에이테크놀로지    207      하락 -57  -21.59%\n",
       "3        동신건설  20700   하락 -5,200  -20.08%\n",
       "4        화천기계   4395   하락 -1,005  -18.61%\n",
       "5         덕성우   9960   하락 -2,220  -18.23%\n",
       "6         에이텍  13820   하락 -2,710  -16.39%\n",
       "7      오리엔트정공   1409     하락 -273  -16.23%\n",
       "8      테고사이언스  20600   하락 -3,600  -14.88%\n",
       "9       태양금속우   3410     하락 -580  -14.54%\n",
       "10     디티앤씨알오   6240   하락 -1,040  -14.29%\n",
       "11       대영포장   1380     하락 -223  -13.91%\n",
       "12  솔루스첨단소재1우   3315     하락 -520  -13.56%\n",
       "13      토탈소프트   4880     하락 -730  -13.01%\n",
       "14    에이텍모빌리티  14000   하락 -1,980  -12.39%"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wtf[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
